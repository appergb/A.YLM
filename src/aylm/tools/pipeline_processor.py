"""æµæ°´çº¿å¤„ç†å™¨æ¨¡å—ã€‚

å®ç°å¤šå›¾åƒæµæ°´çº¿å¤„ç†ï¼š
- æ¨¡å‹åªåŠ è½½ä¸€æ¬¡åˆ°å†…å­˜
- ç¬¬Nå¼ ç…§ç‰‡è¿›è¡ŒSHARPæ¨ç†æ—¶ï¼Œç¬¬N-1å¼ ç…§ç‰‡åŒæ—¶è¿›è¡Œä½“ç´ åŒ–
- æ”¯æŒNå¼ å’ŒN+1çš„æµæ°´çº¿ä½œä¸šæ¨¡å¼
- å¤„ç†å®Œæˆåè‡ªåŠ¨å¸è½½æ¨¡å‹é‡Šæ”¾å†…å­˜
- æ”¯æŒå¼‚æ­¥å¤„ç†æ¨¡å¼

æµæ°´çº¿ç¤ºæ„å›¾:
    æ—¶é—´ â†’
    å›¾ç‰‡1: [====æ¨¡å‹æ¨ç†====][====ä½“ç´ åŒ–====]
    å›¾ç‰‡2:                   [====æ¨¡å‹æ¨ç†====][====ä½“ç´ åŒ–====]
    å›¾ç‰‡3:                                     [====æ¨¡å‹æ¨ç†====][====ä½“ç´ åŒ–====]
    å®Œæˆå: [====å¸è½½æ¨¡å‹====]
"""

import gc
import logging
import threading
import time
from concurrent.futures import Future, ThreadPoolExecutor
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from queue import Queue
from typing import Callable, List, Optional, Tuple

import torch
import torch.nn.functional as F

logger = logging.getLogger(__name__)


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€æšä¸¾ã€‚"""

    PENDING = "pending"  # ç­‰å¾…ä¸­
    PREDICTING = "predicting"  # æ¨¡å‹æ¨ç†ä¸­
    PREDICTED = "predicted"  # æ¨ç†å®Œæˆ
    VOXELIZING = "voxelizing"  # ä½“ç´ åŒ–ä¸­
    COMPLETED = "completed"  # å…¨éƒ¨å®Œæˆ
    FAILED = "failed"  # å¤±è´¥


@dataclass
class ImageTask:
    """å•å¼ å›¾åƒçš„å¤„ç†ä»»åŠ¡ã€‚"""

    image_path: Path
    index: int
    status: TaskStatus = TaskStatus.PENDING
    ply_output_path: Optional[Path] = None
    voxel_output_path: Optional[Path] = None
    predict_start_time: Optional[float] = None
    predict_end_time: Optional[float] = None
    voxel_start_time: Optional[float] = None
    voxel_end_time: Optional[float] = None
    error_message: Optional[str] = None


@dataclass
class PipelineConfig:
    """æµæ°´çº¿é…ç½®ã€‚"""

    voxel_size: float = 0.005  # ä½“ç´ å°ºå¯¸ï¼ˆç±³ï¼‰
    remove_ground: bool = True  # æ˜¯å¦ç§»é™¤åœ°é¢
    transform_coords: bool = False  # æ˜¯å¦è½¬æ¢åæ ‡ç³»
    device: str = "auto"  # è®¾å¤‡é€‰æ‹©
    verbose: bool = True  # è¯¦ç»†è¾“å‡º
    checkpoint_path: Optional[Path] = None  # æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
    auto_unload: bool = True  # å¤„ç†å®Œæˆåè‡ªåŠ¨å¸è½½æ¨¡å‹
    async_mode: bool = False  # å¼‚æ­¥å¤„ç†æ¨¡å¼


@dataclass
class PipelineStats:
    """æµæ°´çº¿ç»Ÿè®¡ä¿¡æ¯ã€‚"""

    total_images: int = 0
    completed_images: int = 0
    failed_images: int = 0
    total_predict_time: float = 0.0
    total_voxel_time: float = 0.0
    pipeline_start_time: Optional[float] = None
    pipeline_end_time: Optional[float] = None

    @property
    def total_time(self) -> float:
        if self.pipeline_start_time and self.pipeline_end_time:
            return self.pipeline_end_time - self.pipeline_start_time
        return 0.0

    @property
    def avg_predict_time(self) -> float:
        if self.completed_images > 0:
            return self.total_predict_time / self.completed_images
        return 0.0

    @property
    def avg_voxel_time(self) -> float:
        if self.completed_images > 0:
            return self.total_voxel_time / self.completed_images
        return 0.0


class PipelineLogger:
    """æµæ°´çº¿æ—¥å¿—è®°å½•å™¨ï¼Œæä¾›è¯¦ç»†çš„æ ¼å¼åŒ–è¾“å‡ºã€‚"""

    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self._lock = threading.Lock()
        self._start_time = time.time()

    def _timestamp(self) -> str:
        """è·å–ç›¸å¯¹æ—¶é—´æˆ³ã€‚"""
        elapsed = time.time() - self._start_time
        return f"[{elapsed:8.2f}s]"

    def _print(self, msg: str, level: str = "INFO"):
        """çº¿ç¨‹å®‰å…¨çš„æ‰“å°ã€‚"""
        with self._lock:
            timestamp = self._timestamp()
            prefix = {
                "INFO": "   ",
                "STAGE": ">>>",
                "OK": " âœ“ ",
                "WARN": " ! ",
                "ERROR": " âœ— ",
                "PROGRESS": " â†’ ",
            }.get(level, "   ")
            print(f"{timestamp} {prefix} {msg}")

    def header(self, title: str):
        """æ‰“å°æ ‡é¢˜å¤´ã€‚"""
        with self._lock:
            print("\n" + "=" * 60)
            print(f"  {title}")
            print("=" * 60)

    def section(self, title: str):
        """æ‰“å°åˆ†èŠ‚æ ‡é¢˜ã€‚"""
        with self._lock:
            print(f"\n{'â”€' * 40}")
            print(f"  {title}")
            print(f"{'â”€' * 40}")

    def stage(self, msg: str):
        """æ‰“å°é˜¶æ®µä¿¡æ¯ã€‚"""
        self._print(msg, "STAGE")

    def info(self, msg: str):
        """æ‰“å°æ™®é€šä¿¡æ¯ã€‚"""
        if self.verbose:
            self._print(msg, "INFO")

    def ok(self, msg: str):
        """æ‰“å°æˆåŠŸä¿¡æ¯ã€‚"""
        self._print(msg, "OK")

    def warn(self, msg: str):
        """æ‰“å°è­¦å‘Šä¿¡æ¯ã€‚"""
        self._print(msg, "WARN")

    def error(self, msg: str):
        """æ‰“å°é”™è¯¯ä¿¡æ¯ã€‚"""
        self._print(msg, "ERROR")

    def progress(self, msg: str):
        """æ‰“å°è¿›åº¦ä¿¡æ¯ã€‚"""
        self._print(msg, "PROGRESS")

    def task_status(self, tasks: List[ImageTask]):
        """æ‰“å°ä»»åŠ¡çŠ¶æ€è¡¨æ ¼ã€‚"""
        with self._lock:
            print("\nâ”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print("â”‚ No. â”‚ æ–‡ä»¶å                     â”‚ çŠ¶æ€        â”‚")
            print("â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
            for task in tasks:
                name = task.image_path.name[:24]
                status_map = {
                    TaskStatus.PENDING: "â³ ç­‰å¾…ä¸­",
                    TaskStatus.PREDICTING: "ğŸ”„ æ¨ç†ä¸­",
                    TaskStatus.PREDICTED: "ğŸ“¦ å¾…ä½“ç´ åŒ–",
                    TaskStatus.VOXELIZING: "ğŸ”„ ä½“ç´ åŒ–ä¸­",
                    TaskStatus.COMPLETED: "âœ… å®Œæˆ",
                    TaskStatus.FAILED: "âŒ å¤±è´¥",
                }
                status = status_map.get(task.status, "æœªçŸ¥")
                print(f"â”‚ {task.index+1:3d} â”‚ {name:<26} â”‚ {status:<11} â”‚")
            print("â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    def stats(self, stats: PipelineStats):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯ã€‚"""
        with self._lock:
            print("\n" + "=" * 60)
            print("  æµæ°´çº¿æ‰§è¡Œç»Ÿè®¡")
            print("=" * 60)
            print(f"  æ€»å›¾åƒæ•°:       {stats.total_images}")
            print(f"  æˆåŠŸå®Œæˆ:       {stats.completed_images}")
            print(f"  å¤±è´¥æ•°é‡:       {stats.failed_images}")
            print("  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            print(f"  æ€»è€—æ—¶:         {stats.total_time:.2f} ç§’")
            print(f"  æ¨ç†æ€»è€—æ—¶:     {stats.total_predict_time:.2f} ç§’")
            print(f"  ä½“ç´ åŒ–æ€»è€—æ—¶:   {stats.total_voxel_time:.2f} ç§’")
            print("  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            print(f"  å¹³å‡æ¨ç†æ—¶é—´:   {stats.avg_predict_time:.2f} ç§’/å¼ ")
            print(f"  å¹³å‡ä½“ç´ åŒ–æ—¶é—´: {stats.avg_voxel_time:.2f} ç§’/å¼ ")
            if stats.total_images > 1:
                # è®¡ç®—æµæ°´çº¿æ•ˆç‡
                sequential_time = (
                    stats.avg_predict_time + stats.avg_voxel_time
                ) * stats.completed_images
                efficiency = (
                    sequential_time / stats.total_time if stats.total_time > 0 else 0
                )
                print(f"  æµæ°´çº¿æ•ˆç‡:     {efficiency:.1%}")
            print("=" * 60 + "\n")


class PipelineProcessor:
    """æµæ°´çº¿å¤„ç†å™¨ã€‚

    å®ç°æ¨¡å‹æ¨ç†å’Œä½“ç´ åŒ–çš„æµæ°´çº¿å¹¶è¡Œå¤„ç†ã€‚
    æ”¯æŒä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œè‡ªåŠ¨æ¸…ç†èµ„æºã€‚

    Example:
        # æ–¹å¼1: ç›´æ¥ä½¿ç”¨ï¼ˆè‡ªåŠ¨å¸è½½ï¼‰
        processor = PipelineProcessor(config)
        stats = processor.process(input_path, output_dir)

        # æ–¹å¼2: ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆæ¨èï¼Œç¡®ä¿èµ„æºé‡Šæ”¾ï¼‰
        with PipelineProcessor(config) as processor:
            stats = processor.process(input_path, output_dir)

        # æ–¹å¼3: å¼‚æ­¥å¤„ç†
        processor = PipelineProcessor(config)
        future = processor.process_async(input_path, output_dir)
        # ... åšå…¶ä»–äº‹æƒ… ...
        stats = future.result()  # ç­‰å¾…å®Œæˆ
    """

    def __init__(self, config: Optional[PipelineConfig] = None):
        self.config = config or PipelineConfig()
        self.log = PipelineLogger(self.config.verbose)
        self.stats = PipelineStats()

        # æ¨¡å‹ç›¸å…³
        self._predictor = None
        self._device = None
        self._model_loaded = False

        # ä½“ç´ åŒ–å™¨
        self._voxelizer = None

        # ä»»åŠ¡ç®¡ç†
        self._tasks: List[ImageTask] = []
        self._predict_queue: Queue = Queue()
        self._voxel_queue: Queue = Queue()

        # çº¿ç¨‹æ§åˆ¶
        self._stop_event = threading.Event()
        self._predict_lock = threading.Lock()

        # å¼‚æ­¥æ‰§è¡Œå™¨
        self._async_executor: Optional[ThreadPoolExecutor] = None
        self._async_future: Optional[Future] = None

    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£ã€‚"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡ºï¼Œç¡®ä¿èµ„æºé‡Šæ”¾ã€‚"""
        self.cleanup()
        return False

    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿èµ„æºé‡Šæ”¾ã€‚"""
        self.cleanup()

    def cleanup(self):
        """æ¸…ç†æ‰€æœ‰èµ„æºã€‚"""
        self._unload_model()
        self._cleanup_voxelizer()
        self._cleanup_async()

    def _unload_model(self):
        """å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾GPU/å†…å­˜ã€‚"""
        if not self._model_loaded:
            return

        self.log.stage("å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾å†…å­˜...")

        try:
            # æ¸…é™¤æ¨¡å‹å¼•ç”¨
            if self._predictor is not None:
                # å°†æ¨¡å‹ç§»åˆ°CPUï¼ˆå¦‚æœåœ¨GPUä¸Šï¼‰
                if self._device and self._device.type != "cpu":
                    try:
                        self._predictor.cpu()
                    except Exception:
                        pass

                # åˆ é™¤æ¨¡å‹
                del self._predictor
                self._predictor = None

            # æ¸…é™¤è®¾å¤‡å¼•ç”¨
            self._device = None
            self._model_loaded = False

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()

            # æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()

            # æ¸…ç†MPSç¼“å­˜ï¼ˆApple Siliconï¼‰
            if hasattr(torch, "mps") and hasattr(torch.mps, "empty_cache"):
                try:
                    torch.mps.empty_cache()
                except Exception:
                    pass

            self.log.ok("æ¨¡å‹å·²å¸è½½ï¼Œå†…å­˜å·²é‡Šæ”¾")

        except Exception as e:
            self.log.warn(f"æ¨¡å‹å¸è½½æ—¶å‡ºç°è­¦å‘Š: {e}")

    def _cleanup_voxelizer(self):
        """æ¸…ç†ä½“ç´ åŒ–å™¨ã€‚"""
        if self._voxelizer is not None:
            del self._voxelizer
            self._voxelizer = None

    def _cleanup_async(self):
        """æ¸…ç†å¼‚æ­¥æ‰§è¡Œå™¨ã€‚"""
        if self._async_executor is not None:
            self._async_executor.shutdown(wait=False)
            self._async_executor = None
        self._async_future = None

    def _detect_device(self) -> torch.device:
        """æ£€æµ‹å¯ç”¨è®¾å¤‡ã€‚"""
        if self.config.device != "auto":
            return torch.device(self.config.device)

        if torch.cuda.is_available():
            return torch.device("cuda")
        elif hasattr(torch, "mps") and torch.mps.is_available():
            return torch.device("mps")
        else:
            return torch.device("cpu")

    def _load_model(self) -> bool:
        """åŠ è½½SHARPæ¨¡å‹åˆ°å†…å­˜ã€‚"""
        self.log.stage("åŠ è½½SHARPæ¨¡å‹åˆ°å†…å­˜...")

        try:
            from sharp.models import PredictorParams, create_predictor

            self._device = self._detect_device()
            self.log.info(f"ä½¿ç”¨è®¾å¤‡: {self._device}")

            # åŠ è½½æ£€æŸ¥ç‚¹
            if self.config.checkpoint_path and self.config.checkpoint_path.exists():
                self.log.info(f"ä»æœ¬åœ°åŠ è½½: {self.config.checkpoint_path}")
                state_dict = torch.load(
                    self.config.checkpoint_path,
                    weights_only=True,
                    map_location=self._device,
                )
            else:
                model_url = (
                    "https://ml-site.cdn-apple.com/models/sharp/sharp_2572gikvuh.pt"
                )
                self.log.info("ä»ç½‘ç»œä¸‹è½½æ¨¡å‹...")
                state_dict = torch.hub.load_state_dict_from_url(
                    model_url, progress=True, map_location=self._device
                )

            # åˆ›å»ºé¢„æµ‹å™¨
            self._predictor = create_predictor(PredictorParams())
            self._predictor.load_state_dict(state_dict)
            self._predictor.eval()
            self._predictor.to(self._device)

            self._model_loaded = True
            self.log.ok("æ¨¡å‹åŠ è½½å®Œæˆ")
            return True

        except ImportError as e:
            self.log.error("æ¨¡å‹åŠ è½½å¤±è´¥: ç¼ºå°‘ä¾èµ–æ¨¡å—")
            self.log.error("    è¯·ç¡®ä¿å·²å®‰è£… sharp åŒ…: pip install sharp")
            self.log.error(f"    è¯¦ç»†ä¿¡æ¯: {e}")
            logger.exception("æ¨¡å‹å¯¼å…¥å¤±è´¥")
            return False
        except Exception as e:
            self.log.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.log.error(f"    é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.exception("æ¨¡å‹åŠ è½½å¼‚å¸¸")
            return False

    def _load_voxelizer(self):
        """åŠ è½½ä½“ç´ åŒ–å™¨ã€‚"""
        from aylm.tools.pointcloud_voxelizer import PointCloudVoxelizer, VoxelizerConfig

        vox_config = VoxelizerConfig(voxel_size=self.config.voxel_size)
        self._voxelizer = PointCloudVoxelizer(config=vox_config)
        self.log.info(f"ä½“ç´ åŒ–å™¨å·²åˆå§‹åŒ– (ä½“ç´ å°ºå¯¸: {self.config.voxel_size}m)")

    @torch.no_grad()
    def _predict_single(self, task: ImageTask, output_dir: Path) -> bool:
        """å¯¹å•å¼ å›¾åƒè¿›è¡Œæ¨¡å‹æ¨ç†ã€‚"""
        from sharp.utils import io
        from sharp.utils.gaussians import save_ply, unproject_gaussians

        task.status = TaskStatus.PREDICTING
        task.predict_start_time = time.time()

        self.log.progress(f"[{task.index+1}] å¼€å§‹æ¨ç†: {task.image_path.name}")

        try:
            # åŠ è½½å›¾åƒ
            image, _, f_px = io.load_rgb(task.image_path)
            height, width = image.shape[:2]

            self.log.info(f"    å›¾åƒå°ºå¯¸: {width}x{height}, ç„¦è·: {f_px:.1f}px")

            # é¢„å¤„ç†
            internal_shape = (1536, 1536)
            image_pt = (
                torch.from_numpy(image.copy()).float().to(self._device).permute(2, 0, 1)
                / 255.0
            )
            disparity_factor = torch.tensor([f_px / width]).float().to(self._device)

            image_resized_pt = F.interpolate(
                image_pt[None],
                size=(internal_shape[1], internal_shape[0]),
                mode="bilinear",
                align_corners=True,
            )

            # æ¨ç†ï¼ˆéœ€è¦é”ä¿æŠ¤ï¼Œå› ä¸ºæ¨¡å‹ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼‰
            with self._predict_lock:
                gaussians_ndc = self._predictor(image_resized_pt, disparity_factor)

            # åå¤„ç†
            intrinsics = (
                torch.tensor(
                    [
                        [f_px, 0, width / 2, 0],
                        [0, f_px, height / 2, 0],
                        [0, 0, 1, 0],
                        [0, 0, 0, 1],
                    ]
                )
                .float()
                .to(self._device)
            )

            intrinsics_resized = intrinsics.clone()
            intrinsics_resized[0] *= internal_shape[0] / width
            intrinsics_resized[1] *= internal_shape[1] / height

            gaussians = unproject_gaussians(
                gaussians_ndc,
                torch.eye(4).to(self._device),
                intrinsics_resized,
                internal_shape,
            )

            # ä¿å­˜PLY
            output_path = output_dir / f"{task.image_path.stem}.ply"
            save_ply(gaussians, f_px, (height, width), output_path)

            task.ply_output_path = output_path
            task.status = TaskStatus.PREDICTED
            task.predict_end_time = time.time()

            predict_time = task.predict_end_time - task.predict_start_time
            self.log.ok(
                f"[{task.index+1}] æ¨ç†å®Œæˆ: {task.image_path.name} ({predict_time:.2f}s)"
            )
            self.log.info(f"    è¾“å‡º: {output_path.name}")

            return True

        except Exception as e:
            task.status = TaskStatus.FAILED
            task.error_message = str(e)
            task.predict_end_time = time.time()
            self.log.error(f"[{task.index+1}] æ¨ç†å¤±è´¥: {task.image_path.name}")
            self.log.error(f"    é”™è¯¯ç±»å‹: {type(e).__name__}")
            self.log.error(f"    é”™è¯¯ä¿¡æ¯: {e}")
            logger.exception(f"æ¨ç†å¼‚å¸¸è¯¦æƒ… - {task.image_path.name}")
            return False

    def _voxelize_single(self, task: ImageTask, output_dir: Path) -> bool:
        """å¯¹å•ä¸ªPLYæ–‡ä»¶è¿›è¡Œä½“ç´ åŒ–ã€‚"""
        if task.status != TaskStatus.PREDICTED or task.ply_output_path is None:
            return False

        task.status = TaskStatus.VOXELIZING
        task.voxel_start_time = time.time()

        self.log.progress(f"[{task.index+1}] å¼€å§‹ä½“ç´ åŒ–: {task.ply_output_path.name}")

        try:
            output_path = output_dir / f"vox_{task.ply_output_path.name}"

            self._voxelizer.process(
                task.ply_output_path,
                output_path,
                remove_ground=self.config.remove_ground,
                transform_coords=self.config.transform_coords,
            )

            task.voxel_output_path = output_path
            task.status = TaskStatus.COMPLETED
            task.voxel_end_time = time.time()

            voxel_time = task.voxel_end_time - task.voxel_start_time
            self.log.ok(
                f"[{task.index+1}] ä½“ç´ åŒ–å®Œæˆ: {task.ply_output_path.name} ({voxel_time:.2f}s)"
            )
            self.log.info(f"    è¾“å‡º: {output_path.name}")

            return True

        except Exception as e:
            task.status = TaskStatus.FAILED
            task.error_message = str(e)
            task.voxel_end_time = time.time()
            self.log.error(f"[{task.index+1}] ä½“ç´ åŒ–å¤±è´¥: {task.ply_output_path.name}")
            self.log.error(f"    é”™è¯¯ç±»å‹: {type(e).__name__}")
            self.log.error(f"    é”™è¯¯ä¿¡æ¯: {e}")
            logger.exception(f"ä½“ç´ åŒ–å¼‚å¸¸è¯¦æƒ… - {task.ply_output_path.name}")
            return False

    def _collect_images(self, input_path: Path) -> List[Path]:
        """æ”¶é›†è¾“å…¥ç›®å½•ä¸­çš„å›¾åƒæ–‡ä»¶ã€‚"""
        extensions = {".jpg", ".jpeg", ".png", ".heic", ".webp", ".tiff", ".bmp"}

        if input_path.is_file():
            if input_path.suffix.lower() in extensions:
                return [input_path]
            return []

        images = []
        for ext in extensions:
            images.extend(input_path.glob(f"*{ext}"))
            images.extend(input_path.glob(f"*{ext.upper()}"))

        return sorted(images)

    def process(
        self,
        input_path: Path,
        output_dir: Path,
        voxel_output_dir: Optional[Path] = None,
    ) -> PipelineStats:
        """æ‰§è¡Œæµæ°´çº¿å¤„ç†ã€‚

        Args:
            input_path: è¾“å…¥å›¾åƒè·¯å¾„æˆ–ç›®å½•
            output_dir: PLYè¾“å‡ºç›®å½•
            voxel_output_dir: ä½“ç´ åŒ–è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä¸ºoutput_dir/voxelizedï¼‰

        Returns:
            PipelineStats: å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        """
        self.log.header("A.YLM æµæ°´çº¿å¤„ç†å™¨ v2.0")

        # åˆå§‹åŒ–
        self.stats = PipelineStats()
        self.stats.pipeline_start_time = time.time()

        # éªŒè¯è¾“å…¥è·¯å¾„
        if not input_path.exists():
            self.log.error(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
            self.stats.pipeline_end_time = time.time()
            return self.stats

        if voxel_output_dir is None:
            voxel_output_dir = output_dir / "voxelized"

        # åˆ›å»ºè¾“å‡ºç›®å½•
        try:
            output_dir.mkdir(parents=True, exist_ok=True)
            voxel_output_dir.mkdir(parents=True, exist_ok=True)
            self.log.info(f"PLYè¾“å‡ºç›®å½•: {output_dir}")
            self.log.info(f"ä½“ç´ åŒ–è¾“å‡ºç›®å½•: {voxel_output_dir}")
        except PermissionError as e:
            self.log.error(f"æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {e}")
            self.stats.pipeline_end_time = time.time()
            return self.stats

        # æ”¶é›†å›¾åƒ
        self.log.section("é˜¶æ®µ 1: æ”¶é›†å›¾åƒ")
        image_paths = self._collect_images(input_path)

        if not image_paths:
            self.log.error(f"æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {input_path}")
            return self.stats

        self.stats.total_images = len(image_paths)
        self.log.ok(f"æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒ")

        for i, path in enumerate(image_paths):
            self.log.info(f"  [{i+1}] {path.name}")

        # åˆ›å»ºä»»åŠ¡
        self._tasks = [
            ImageTask(image_path=path, index=i) for i, path in enumerate(image_paths)
        ]

        # åŠ è½½æ¨¡å‹
        self.log.section("é˜¶æ®µ 2: åŠ è½½æ¨¡å‹")
        if not self._load_model():
            self.log.error("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢å¤„ç†")
            return self.stats

        # åŠ è½½ä½“ç´ åŒ–å™¨
        self._load_voxelizer()

        # æ‰§è¡Œæµæ°´çº¿
        self.log.section("é˜¶æ®µ 3: æµæ°´çº¿å¤„ç†")
        self.log.info("æµæ°´çº¿æ¨¡å¼: æ¨ç†(N) || ä½“ç´ åŒ–(N-1)")
        self.log.info("")

        self._execute_pipeline(output_dir, voxel_output_dir)

        # ç»Ÿè®¡ç»“æœ
        self.stats.pipeline_end_time = time.time()

        for task in self._tasks:
            if task.status == TaskStatus.COMPLETED:
                self.stats.completed_images += 1
                if task.predict_start_time and task.predict_end_time:
                    self.stats.total_predict_time += (
                        task.predict_end_time - task.predict_start_time
                    )
                if task.voxel_start_time and task.voxel_end_time:
                    self.stats.total_voxel_time += (
                        task.voxel_end_time - task.voxel_start_time
                    )
            elif task.status == TaskStatus.FAILED:
                self.stats.failed_images += 1

        # æ‰“å°æœ€ç»ˆçŠ¶æ€
        self.log.section("å¤„ç†ç»“æœ")
        self.log.task_status(self._tasks)
        self.log.stats(self.stats)

        # è‡ªåŠ¨å¸è½½æ¨¡å‹
        if self.config.auto_unload:
            self.log.section("é˜¶æ®µ 4: æ¸…ç†èµ„æº")
            self._unload_model()
            self._cleanup_voxelizer()

        return self.stats

    def process_async(
        self,
        input_path: Path,
        output_dir: Path,
        voxel_output_dir: Optional[Path] = None,
        callback: Optional[Callable[[PipelineStats], None]] = None,
    ) -> Future:
        """å¼‚æ­¥æ‰§è¡Œæµæ°´çº¿å¤„ç†ã€‚

        åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œå¤„ç†ï¼Œç«‹å³è¿”å› Future å¯¹è±¡ã€‚

        Args:
            input_path: è¾“å…¥å›¾åƒè·¯å¾„æˆ–ç›®å½•
            output_dir: PLYè¾“å‡ºç›®å½•
            voxel_output_dir: ä½“ç´ åŒ–è¾“å‡ºç›®å½•
            callback: å¤„ç†å®Œæˆåçš„å›è°ƒå‡½æ•°

        Returns:
            Future: å¯ç”¨äºè·å–ç»“æœæˆ–æ£€æŸ¥çŠ¶æ€

        Example:
            >>> processor = PipelineProcessor(config)
            >>> future = processor.process_async(input_path, output_dir)
            >>> # åšå…¶ä»–äº‹æƒ…...
            >>> if future.done():
            ...     stats = future.result()
            >>> # æˆ–è€…ç­‰å¾…å®Œæˆ
            >>> stats = future.result(timeout=300)
        """
        if self._async_executor is None:
            self._async_executor = ThreadPoolExecutor(
                max_workers=1, thread_name_prefix="pipeline"
            )

        def _run():
            try:
                stats = self.process(input_path, output_dir, voxel_output_dir)
                if callback:
                    callback(stats)
                return stats
            except Exception:
                logger.exception("å¼‚æ­¥å¤„ç†å¤±è´¥")
                raise

        self._async_future = self._async_executor.submit(_run)
        return self._async_future

    def is_processing(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†ä¸­ã€‚"""
        if self._async_future is None:
            return False
        return not self._async_future.done()

    def wait_for_completion(
        self, timeout: Optional[float] = None
    ) -> Optional[PipelineStats]:
        """ç­‰å¾…å¼‚æ­¥å¤„ç†å®Œæˆã€‚

        Args:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNone è¡¨ç¤ºæ— é™ç­‰å¾…

        Returns:
            PipelineStats æˆ– Noneï¼ˆå¦‚æœè¶…æ—¶ï¼‰
        """
        if self._async_future is None:
            return None
        try:
            return self._async_future.result(timeout=timeout)
        except TimeoutError:
            return None

    def cancel(self) -> bool:
        """å–æ¶ˆæ­£åœ¨è¿›è¡Œçš„å¤„ç†ã€‚"""
        self._stop_event.set()
        if self._async_future is not None:
            return self._async_future.cancel()
        return False

    def _execute_pipeline(self, output_dir: Path, voxel_output_dir: Path):
        """æ‰§è¡Œæµæ°´çº¿å¤„ç†é€»è¾‘ã€‚

        æµæ°´çº¿ç­–ç•¥:
        1. ç¬¬ä¸€å¼ å›¾ç‰‡: åªåšæ¨ç†ï¼ˆæ— å¹¶è¡Œï¼‰
        2. ç¬¬2åˆ°Nå¼ å›¾ç‰‡: æ¨ç†ç¬¬Nå¼  || ä½“ç´ åŒ–ç¬¬N-1å¼ ï¼ˆå¹¶è¡Œï¼‰
        3. æœ€å: ä½“ç´ åŒ–æœ€åä¸€å¼ å›¾ç‰‡ï¼ˆæ— å¹¶è¡Œï¼‰

        æ—¶é—´çº¿ç¤ºæ„:
            å›¾ç‰‡1: [====æ¨ç†====]
            å›¾ç‰‡2:              [====æ¨ç†====]
            å›¾ç‰‡1:              [====ä½“ç´ åŒ–====]
            å›¾ç‰‡3:                            [====æ¨ç†====]
            å›¾ç‰‡2:                            [====ä½“ç´ åŒ–====]
            ...
        """
        total = len(self._tasks)

        if total == 0:
            self.log.warn("æ²¡æœ‰ä»»åŠ¡éœ€è¦å¤„ç†")
            return

        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä½“ç´ åŒ–ï¼ˆæ¨ç†åœ¨ä¸»çº¿ç¨‹ï¼Œå› ä¸ºGPUæ“ä½œéœ€è¦åŒæ­¥ï¼‰
        with ThreadPoolExecutor(max_workers=1) as voxel_executor:
            voxel_future: Optional[Future] = None
            prev_task_for_voxel: Optional[ImageTask] = None

            for i, task in enumerate(self._tasks):
                self.log.info(f"\n{'â”€' * 40}")
                self.log.info(f"å¤„ç†è¿›åº¦: {i+1}/{total}")

                # æ˜¾ç¤ºå½“å‰é˜¶æ®µçš„å¹¶è¡ŒçŠ¶æ€
                if i == 0:
                    self.log.info("  é˜¶æ®µ: æ¨ç†ç¬¬1å¼ ï¼ˆæ— å¹¶è¡Œï¼‰")
                elif i < total:
                    self.log.info(f"  é˜¶æ®µ: æ¨ç†ç¬¬{i+1}å¼  || ä½“ç´ åŒ–ç¬¬{i}å¼ ï¼ˆå¹¶è¡Œï¼‰")

                # å¦‚æœæœ‰ä¸Šä¸€å¼ å›¾ç‰‡éœ€è¦ä½“ç´ åŒ–ï¼Œå¯åŠ¨å¼‚æ­¥ä½“ç´ åŒ–
                if prev_task_for_voxel is not None:
                    self.log.progress(
                        f"  å¯åŠ¨å¹¶è¡Œä½“ç´ åŒ–: [{prev_task_for_voxel.index+1}] {prev_task_for_voxel.image_path.name}"
                    )
                    voxel_future = voxel_executor.submit(
                        self._voxelize_single, prev_task_for_voxel, voxel_output_dir
                    )

                # æ‰§è¡Œå½“å‰å›¾ç‰‡çš„æ¨ç†ï¼ˆä¸»çº¿ç¨‹ï¼‰
                predict_success = self._predict_single(task, output_dir)

                # ç­‰å¾…å¹¶è¡Œçš„ä½“ç´ åŒ–å®Œæˆï¼ˆå¦‚æœæœ‰ï¼‰
                if voxel_future is not None:
                    try:
                        voxel_future.result()
                    except Exception as e:
                        self.log.error(f"ä½“ç´ åŒ–ä»»åŠ¡å¼‚å¸¸: {e}")
                    voxel_future = None

                # è®°å½•å½“å‰ä»»åŠ¡ç”¨äºä¸‹ä¸€è½®çš„ä½“ç´ åŒ–
                if predict_success:
                    prev_task_for_voxel = task
                else:
                    prev_task_for_voxel = None

            # å¤„ç†æœ€åä¸€å¼ å›¾ç‰‡çš„ä½“ç´ åŒ–ï¼ˆåŒæ­¥æ‰§è¡Œï¼Œæ— å¹¶è¡Œï¼‰
            if prev_task_for_voxel is not None:
                self.log.info(f"\n{'â”€' * 40}")
                self.log.info("æœ€ç»ˆé˜¶æ®µ: ä½“ç´ åŒ–æœ€åä¸€å¼ å›¾ç‰‡")
                self._voxelize_single(prev_task_for_voxel, voxel_output_dir)


def run_pipeline(
    input_path: str,
    output_dir: str,
    voxel_size: float = 0.005,
    checkpoint_path: Optional[str] = None,
    verbose: bool = True,
    auto_unload: bool = True,
) -> PipelineStats:
    """ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œæµæ°´çº¿å¤„ç†ã€‚

    Args:
        input_path: è¾“å…¥å›¾åƒè·¯å¾„æˆ–ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        voxel_size: ä½“ç´ å°ºå¯¸ï¼ˆç±³ï¼‰
        checkpoint_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
        auto_unload: å¤„ç†å®Œæˆåè‡ªåŠ¨å¸è½½æ¨¡å‹ï¼ˆé»˜è®¤Trueï¼‰

    Returns:
        PipelineStats: å¤„ç†ç»Ÿè®¡ä¿¡æ¯

    Example:
        >>> from aylm.tools.pipeline_processor import run_pipeline
        >>> stats = run_pipeline(
        ...     input_path="inputs/input_images",
        ...     output_dir="outputs/output_gaussians",
        ...     voxel_size=0.005,
        ...     verbose=True
        ... )
        >>> print(f"å¤„ç†å®Œæˆ: {stats.completed_images}/{stats.total_images}")
    """
    config = PipelineConfig(
        voxel_size=voxel_size,
        checkpoint_path=Path(checkpoint_path) if checkpoint_path else None,
        verbose=verbose,
        auto_unload=auto_unload,
    )

    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºé‡Šæ”¾
    with PipelineProcessor(config) as processor:
        return processor.process(Path(input_path), Path(output_dir))


def run_pipeline_async(
    input_path: str,
    output_dir: str,
    voxel_size: float = 0.005,
    checkpoint_path: Optional[str] = None,
    verbose: bool = True,
    callback: Optional[Callable[[PipelineStats], None]] = None,
) -> Tuple["PipelineProcessor", Future]:
    """ä¾¿æ·å‡½æ•°ï¼šå¼‚æ­¥è¿è¡Œæµæ°´çº¿å¤„ç†ã€‚

    Args:
        input_path: è¾“å…¥å›¾åƒè·¯å¾„æˆ–ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        voxel_size: ä½“ç´ å°ºå¯¸ï¼ˆç±³ï¼‰
        checkpoint_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
        callback: å¤„ç†å®Œæˆåçš„å›è°ƒå‡½æ•°

    Returns:
        Tuple[PipelineProcessor, Future]: å¤„ç†å™¨å®ä¾‹å’ŒFutureå¯¹è±¡

    Example:
        >>> from aylm.tools.pipeline_processor import run_pipeline_async
        >>> processor, future = run_pipeline_async(
        ...     input_path="inputs/input_images",
        ...     output_dir="outputs/output_gaussians",
        ...     callback=lambda stats: print(f"å®Œæˆ: {stats.completed_images}å¼ ")
        ... )
        >>> # åšå…¶ä»–äº‹æƒ…...
        >>> stats = future.result()  # ç­‰å¾…å®Œæˆ
        >>> processor.cleanup()  # æ‰‹åŠ¨æ¸…ç†ï¼ˆæˆ–è®©processorè¢«åƒåœ¾å›æ”¶ï¼‰
    """
    config = PipelineConfig(
        voxel_size=voxel_size,
        checkpoint_path=Path(checkpoint_path) if checkpoint_path else None,
        verbose=verbose,
        auto_unload=True,  # å¼‚æ­¥æ¨¡å¼ä¸‹ä¹Ÿè‡ªåŠ¨å¸è½½
    )

    processor = PipelineProcessor(config)
    future = processor.process_async(
        Path(input_path), Path(output_dir), callback=callback
    )
    return processor, future


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    import sys

    if len(sys.argv) < 3:
        print("ç”¨æ³•: python pipeline_processor.py <è¾“å…¥ç›®å½•> <è¾“å‡ºç›®å½•>")
        sys.exit(1)

    stats = run_pipeline(sys.argv[1], sys.argv[2])
    sys.exit(0 if stats.failed_images == 0 else 1)
